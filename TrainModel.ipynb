{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73b1e66a-7b6e-4eb9-b85a-da7252517c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "from utils.process import Assemble\n",
    "from utils.train import Build\n",
    "\n",
    "assemble = Assemble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34266845-9d1a-4552-aaa7-818310f88246",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.pickle', 'rb') as f:\n",
    "    test_dict = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23cdb282-db3c-4d7a-a1d9-e064d544b48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [[{'model': 'LR1', 'parameters': {}}, {'feature_selection': ['SFM1', {}], 'dimensionality_reduction': ['PCA1', {}]}],\n",
    "          [{'model': 'RFR1', 'parameters': {'n_estimators': 20, 'criterion':'squared_error', 'verbose':1}}, \n",
    "           {'feature_selection': ['RFE1', {'n_features_to_select': 3, 'step':1}], 'dimensionality_reduction': ['PCA1', {}]}],\n",
    "          [{'model': 'XGB1', 'parameters': {}}, {'feature_selection': ['SKB1',{}], 'dimensionality_reduction': ['KPCA1', {}]}],\n",
    "          [{'model':'SVR1', 'parameters':{}}, {'feature_selection': ['SFS1',{}], 'dimensionality_reduction': ['SPCA1', {}]}],\n",
    "          [{'model':'PLS1', 'parameters':{}}, {'feature_selection': ['SKB1',{}], 'dimensionality_reduction': ['PCA1', {}]}],\n",
    "          [{'model':'GBR1', 'parameters':{}}, {'feature_selection': ['RFE1', {'n_features_to_select': 3, 'step':1}], 'dimensionality_reduction': ['KPCA1', {}]}]\n",
    "         ]   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8c9953-57e2-4e28-8311-c355ca406b04",
   "metadata": {},
   "source": [
    "# Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be2d7875-593f-4adc-883a-c1a53ec45784",
   "metadata": {},
   "outputs": [],
   "source": [
    "build = Build(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd94bba1-082b-4e4e-94cd-ec885f0e030d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training regression model LR1 for DF1\n",
      "Training done!\n",
      "\n",
      "Training regression model RFR1 for DF1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:   18.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done!\n",
      "\n",
      "Training regression model XGB1 for DF1\n",
      "Training done!\n",
      "\n",
      "Training regression model SVR1 for DF1\n",
      "Training done!\n",
      "\n",
      "Training regression model PLS1 for DF1\n",
      "Training done!\n",
      "\n",
      "Training regression model GBR1 for DF1\n",
      "Training done!\n",
      "\n",
      "Training regression model LR1 for DF2\n",
      "Training done!\n",
      "\n",
      "Training regression model RFR1 for DF2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    8.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done!\n",
      "\n",
      "Training regression model XGB1 for DF2\n",
      "Training done!\n",
      "\n",
      "Training regression model SVR1 for DF2\n",
      "Training done!\n",
      "\n",
      "Training regression model PLS1 for DF2\n",
      "Training done!\n",
      "\n",
      "Training regression model GBR1 for DF2\n",
      "Training done!\n",
      "\n",
      "Training regression model LR1 for DF3\n",
      "Training done!\n",
      "\n",
      "Training regression model RFR1 for DF3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done!\n",
      "\n",
      "Training regression model XGB1 for DF3\n",
      "Training done!\n",
      "\n",
      "Training regression model SVR1 for DF3\n",
      "Training done!\n",
      "\n",
      "Training regression model PLS1 for DF3\n",
      "Training done!\n",
      "\n",
      "Training regression model GBR1 for DF3\n",
      "Training done!\n",
      "\n",
      "Training regression model LR1 for DF4\n",
      "Training done!\n",
      "\n",
      "Training regression model RFR1 for DF4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done!\n",
      "\n",
      "Training regression model XGB1 for DF4\n",
      "Training done!\n",
      "\n",
      "Training regression model SVR1 for DF4\n",
      "Training done!\n",
      "\n",
      "Training regression model PLS1 for DF4\n",
      "Training done!\n",
      "\n",
      "Training regression model GBR1 for DF4\n",
      "Training done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build.build_regression_models(models, 'Satış')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb3bd3b9-f5f1-4929-8848-d2ff26903db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tables_dict = assemble.assemble_test_tables(test_dict)\n",
    "test_dict['test_tables'] = test_tables_dict\n",
    "error_values_df = assemble.assemble_error_values(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7751020a-0a7d-46a2-95af-89013e0c27c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEPE</th>\n",
       "      <th>MPE</th>\n",
       "      <th>MEAE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>NRMSE</th>\n",
       "      <th>STD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DF1XGB1</th>\n",
       "      <td>8.303</td>\n",
       "      <td>10.123</td>\n",
       "      <td>11.810</td>\n",
       "      <td>17.519</td>\n",
       "      <td>635.749</td>\n",
       "      <td>25.214</td>\n",
       "      <td>0.027769</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF2XGB1</th>\n",
       "      <td>9.122</td>\n",
       "      <td>10.919</td>\n",
       "      <td>13.848</td>\n",
       "      <td>18.747</td>\n",
       "      <td>681.003</td>\n",
       "      <td>26.096</td>\n",
       "      <td>0.028740</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF4XGB1</th>\n",
       "      <td>10.621</td>\n",
       "      <td>12.510</td>\n",
       "      <td>15.200</td>\n",
       "      <td>21.433</td>\n",
       "      <td>905.217</td>\n",
       "      <td>30.087</td>\n",
       "      <td>0.033135</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF3XGB1</th>\n",
       "      <td>11.008</td>\n",
       "      <td>12.661</td>\n",
       "      <td>15.261</td>\n",
       "      <td>22.029</td>\n",
       "      <td>979.053</td>\n",
       "      <td>31.290</td>\n",
       "      <td>0.034460</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF4GBR1</th>\n",
       "      <td>11.110</td>\n",
       "      <td>13.421</td>\n",
       "      <td>15.902</td>\n",
       "      <td>22.010</td>\n",
       "      <td>914.929</td>\n",
       "      <td>30.248</td>\n",
       "      <td>0.033313</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF3GBR1</th>\n",
       "      <td>11.218</td>\n",
       "      <td>13.493</td>\n",
       "      <td>16.148</td>\n",
       "      <td>22.100</td>\n",
       "      <td>925.053</td>\n",
       "      <td>30.415</td>\n",
       "      <td>0.033497</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF2GBR1</th>\n",
       "      <td>11.246</td>\n",
       "      <td>13.663</td>\n",
       "      <td>15.972</td>\n",
       "      <td>22.071</td>\n",
       "      <td>921.055</td>\n",
       "      <td>30.349</td>\n",
       "      <td>0.033424</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF1GBR1</th>\n",
       "      <td>11.270</td>\n",
       "      <td>14.383</td>\n",
       "      <td>16.497</td>\n",
       "      <td>22.860</td>\n",
       "      <td>1002.604</td>\n",
       "      <td>31.664</td>\n",
       "      <td>0.034872</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF3RFR1</th>\n",
       "      <td>11.422</td>\n",
       "      <td>13.699</td>\n",
       "      <td>16.567</td>\n",
       "      <td>23.848</td>\n",
       "      <td>1156.904</td>\n",
       "      <td>34.013</td>\n",
       "      <td>0.037459</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF4RFR1</th>\n",
       "      <td>11.667</td>\n",
       "      <td>13.655</td>\n",
       "      <td>16.850</td>\n",
       "      <td>23.845</td>\n",
       "      <td>1116.159</td>\n",
       "      <td>33.409</td>\n",
       "      <td>0.036794</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF2RFR1</th>\n",
       "      <td>11.752</td>\n",
       "      <td>13.420</td>\n",
       "      <td>17.050</td>\n",
       "      <td>23.589</td>\n",
       "      <td>1098.269</td>\n",
       "      <td>33.140</td>\n",
       "      <td>0.036498</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF1RFR1</th>\n",
       "      <td>11.939</td>\n",
       "      <td>14.047</td>\n",
       "      <td>17.550</td>\n",
       "      <td>24.960</td>\n",
       "      <td>1236.339</td>\n",
       "      <td>35.162</td>\n",
       "      <td>0.038725</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF3SVR1</th>\n",
       "      <td>14.700</td>\n",
       "      <td>20.208</td>\n",
       "      <td>21.363</td>\n",
       "      <td>33.155</td>\n",
       "      <td>2919.581</td>\n",
       "      <td>54.033</td>\n",
       "      <td>0.059508</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF4SVR1</th>\n",
       "      <td>15.112</td>\n",
       "      <td>20.462</td>\n",
       "      <td>21.774</td>\n",
       "      <td>33.767</td>\n",
       "      <td>3030.108</td>\n",
       "      <td>55.046</td>\n",
       "      <td>0.060623</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF3PLS1</th>\n",
       "      <td>15.528</td>\n",
       "      <td>33.114</td>\n",
       "      <td>25.560</td>\n",
       "      <td>33.441</td>\n",
       "      <td>2153.993</td>\n",
       "      <td>46.411</td>\n",
       "      <td>0.051113</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF1LR1</th>\n",
       "      <td>15.531</td>\n",
       "      <td>26.204</td>\n",
       "      <td>25.488</td>\n",
       "      <td>31.421</td>\n",
       "      <td>1718.643</td>\n",
       "      <td>41.457</td>\n",
       "      <td>0.045657</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF4LR1</th>\n",
       "      <td>15.571</td>\n",
       "      <td>27.887</td>\n",
       "      <td>23.969</td>\n",
       "      <td>32.087</td>\n",
       "      <td>1906.028</td>\n",
       "      <td>43.658</td>\n",
       "      <td>0.048081</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF3LR1</th>\n",
       "      <td>15.581</td>\n",
       "      <td>27.905</td>\n",
       "      <td>24.031</td>\n",
       "      <td>32.098</td>\n",
       "      <td>1906.810</td>\n",
       "      <td>43.667</td>\n",
       "      <td>0.048091</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF4PLS1</th>\n",
       "      <td>15.680</td>\n",
       "      <td>33.089</td>\n",
       "      <td>25.618</td>\n",
       "      <td>33.446</td>\n",
       "      <td>2151.628</td>\n",
       "      <td>46.386</td>\n",
       "      <td>0.051086</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF2LR1</th>\n",
       "      <td>15.903</td>\n",
       "      <td>27.732</td>\n",
       "      <td>25.486</td>\n",
       "      <td>31.925</td>\n",
       "      <td>1803.623</td>\n",
       "      <td>42.469</td>\n",
       "      <td>0.046772</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF2PLS1</th>\n",
       "      <td>16.187</td>\n",
       "      <td>32.418</td>\n",
       "      <td>26.404</td>\n",
       "      <td>34.158</td>\n",
       "      <td>2133.740</td>\n",
       "      <td>46.192</td>\n",
       "      <td>0.050872</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF1PLS1</th>\n",
       "      <td>16.576</td>\n",
       "      <td>31.433</td>\n",
       "      <td>27.068</td>\n",
       "      <td>34.227</td>\n",
       "      <td>2087.575</td>\n",
       "      <td>45.690</td>\n",
       "      <td>0.050319</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF2SVR1</th>\n",
       "      <td>17.489</td>\n",
       "      <td>24.174</td>\n",
       "      <td>25.370</td>\n",
       "      <td>39.571</td>\n",
       "      <td>4054.757</td>\n",
       "      <td>63.677</td>\n",
       "      <td>0.070129</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF1SVR1</th>\n",
       "      <td>24.023</td>\n",
       "      <td>32.127</td>\n",
       "      <td>34.307</td>\n",
       "      <td>51.935</td>\n",
       "      <td>6204.232</td>\n",
       "      <td>78.767</td>\n",
       "      <td>0.086748</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MEPE     MPE    MEAE     MAE       MSE    RMSE     NRMSE      STD\n",
       "ALGORITHM                                                                     \n",
       "DF1XGB1     8.303  10.123  11.810  17.519   635.749  25.214  0.027769  109.719\n",
       "DF2XGB1     9.122  10.919  13.848  18.747   681.003  26.096  0.028740  109.719\n",
       "DF4XGB1    10.621  12.510  15.200  21.433   905.217  30.087  0.033135  109.719\n",
       "DF3XGB1    11.008  12.661  15.261  22.029   979.053  31.290  0.034460  109.719\n",
       "DF4GBR1    11.110  13.421  15.902  22.010   914.929  30.248  0.033313  109.719\n",
       "DF3GBR1    11.218  13.493  16.148  22.100   925.053  30.415  0.033497  109.719\n",
       "DF2GBR1    11.246  13.663  15.972  22.071   921.055  30.349  0.033424  109.719\n",
       "DF1GBR1    11.270  14.383  16.497  22.860  1002.604  31.664  0.034872  109.719\n",
       "DF3RFR1    11.422  13.699  16.567  23.848  1156.904  34.013  0.037459  109.719\n",
       "DF4RFR1    11.667  13.655  16.850  23.845  1116.159  33.409  0.036794  109.719\n",
       "DF2RFR1    11.752  13.420  17.050  23.589  1098.269  33.140  0.036498  109.719\n",
       "DF1RFR1    11.939  14.047  17.550  24.960  1236.339  35.162  0.038725  109.719\n",
       "DF3SVR1    14.700  20.208  21.363  33.155  2919.581  54.033  0.059508  109.719\n",
       "DF4SVR1    15.112  20.462  21.774  33.767  3030.108  55.046  0.060623  109.719\n",
       "DF3PLS1    15.528  33.114  25.560  33.441  2153.993  46.411  0.051113  109.719\n",
       "DF1LR1     15.531  26.204  25.488  31.421  1718.643  41.457  0.045657  109.719\n",
       "DF4LR1     15.571  27.887  23.969  32.087  1906.028  43.658  0.048081  109.719\n",
       "DF3LR1     15.581  27.905  24.031  32.098  1906.810  43.667  0.048091  109.719\n",
       "DF4PLS1    15.680  33.089  25.618  33.446  2151.628  46.386  0.051086  109.719\n",
       "DF2LR1     15.903  27.732  25.486  31.925  1803.623  42.469  0.046772  109.719\n",
       "DF2PLS1    16.187  32.418  26.404  34.158  2133.740  46.192  0.050872  109.719\n",
       "DF1PLS1    16.576  31.433  27.068  34.227  2087.575  45.690  0.050319  109.719\n",
       "DF2SVR1    17.489  24.174  25.370  39.571  4054.757  63.677  0.070129  109.719\n",
       "DF1SVR1    24.023  32.127  34.307  51.935  6204.232  78.767  0.086748  109.719"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_values_df.sort_values('MEPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abbc2bef-a6a7-4e7e-8f23-698ed835b961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "      <th>R2^</th>\n",
       "      <th>EVS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DF2XGB1</th>\n",
       "      <td>0.943406</td>\n",
       "      <td>0.933086</td>\n",
       "      <td>0.943428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF1XGB1</th>\n",
       "      <td>0.947167</td>\n",
       "      <td>0.931599</td>\n",
       "      <td>0.947177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF4XGB1</th>\n",
       "      <td>0.924773</td>\n",
       "      <td>0.924395</td>\n",
       "      <td>0.924811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF4GBR1</th>\n",
       "      <td>0.923966</td>\n",
       "      <td>0.923584</td>\n",
       "      <td>0.923974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF3GBR1</th>\n",
       "      <td>0.923125</td>\n",
       "      <td>0.922771</td>\n",
       "      <td>0.923143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF3XGB1</th>\n",
       "      <td>0.918637</td>\n",
       "      <td>0.918262</td>\n",
       "      <td>0.918664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF2GBR1</th>\n",
       "      <td>0.923457</td>\n",
       "      <td>0.909499</td>\n",
       "      <td>0.923463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF4RFR1</th>\n",
       "      <td>0.907243</td>\n",
       "      <td>0.906777</td>\n",
       "      <td>0.907277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF3RFR1</th>\n",
       "      <td>0.903857</td>\n",
       "      <td>0.903414</td>\n",
       "      <td>0.903905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF1GBR1</th>\n",
       "      <td>0.916680</td>\n",
       "      <td>0.892129</td>\n",
       "      <td>0.916681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF2RFR1</th>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.892086</td>\n",
       "      <td>0.908878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF1RFR1</th>\n",
       "      <td>0.897256</td>\n",
       "      <td>0.866981</td>\n",
       "      <td>0.897427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF3LR1</th>\n",
       "      <td>0.841537</td>\n",
       "      <td>0.840807</td>\n",
       "      <td>0.841571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF4LR1</th>\n",
       "      <td>0.841602</td>\n",
       "      <td>0.840806</td>\n",
       "      <td>0.841635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF2LR1</th>\n",
       "      <td>0.850112</td>\n",
       "      <td>0.822780</td>\n",
       "      <td>0.850132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF4PLS1</th>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.820293</td>\n",
       "      <td>0.821197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF3PLS1</th>\n",
       "      <td>0.820995</td>\n",
       "      <td>0.820171</td>\n",
       "      <td>0.820999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF1LR1</th>\n",
       "      <td>0.857175</td>\n",
       "      <td>0.815090</td>\n",
       "      <td>0.857175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF2PLS1</th>\n",
       "      <td>0.822679</td>\n",
       "      <td>0.790343</td>\n",
       "      <td>0.822683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF1PLS1</th>\n",
       "      <td>0.826515</td>\n",
       "      <td>0.775396</td>\n",
       "      <td>0.826516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF3SVR1</th>\n",
       "      <td>0.757372</td>\n",
       "      <td>0.756255</td>\n",
       "      <td>0.764457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF4SVR1</th>\n",
       "      <td>0.748187</td>\n",
       "      <td>0.746921</td>\n",
       "      <td>0.756226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF2SVR1</th>\n",
       "      <td>0.663035</td>\n",
       "      <td>0.601588</td>\n",
       "      <td>0.680853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF1SVR1</th>\n",
       "      <td>0.484406</td>\n",
       "      <td>0.332483</td>\n",
       "      <td>0.526205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 R2       R2^       EVS\n",
       "ALGORITHM                              \n",
       "DF2XGB1    0.943406  0.933086  0.943428\n",
       "DF1XGB1    0.947167  0.931599  0.947177\n",
       "DF4XGB1    0.924773  0.924395  0.924811\n",
       "DF4GBR1    0.923966  0.923584  0.923974\n",
       "DF3GBR1    0.923125  0.922771  0.923143\n",
       "DF3XGB1    0.918637  0.918262  0.918664\n",
       "DF2GBR1    0.923457  0.909499  0.923463\n",
       "DF4RFR1    0.907243  0.906777  0.907277\n",
       "DF3RFR1    0.903857  0.903414  0.903905\n",
       "DF1GBR1    0.916680  0.892129  0.916681\n",
       "DF2RFR1    0.908730  0.892086  0.908878\n",
       "DF1RFR1    0.897256  0.866981  0.897427\n",
       "DF3LR1     0.841537  0.840807  0.841571\n",
       "DF4LR1     0.841602  0.840806  0.841635\n",
       "DF2LR1     0.850112  0.822780  0.850132\n",
       "DF4PLS1    0.821192  0.820293  0.821197\n",
       "DF3PLS1    0.820995  0.820171  0.820999\n",
       "DF1LR1     0.857175  0.815090  0.857175\n",
       "DF2PLS1    0.822679  0.790343  0.822683\n",
       "DF1PLS1    0.826515  0.775396  0.826516\n",
       "DF3SVR1    0.757372  0.756255  0.764457\n",
       "DF4SVR1    0.748187  0.746921  0.756226\n",
       "DF2SVR1    0.663035  0.601588  0.680853\n",
       "DF1SVR1    0.484406  0.332483  0.526205"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variability_values_df = assemble.assemble_variability_values(test_dict)\n",
    "variability_values_df.sort_values('R2^', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7487a43-16d5-4f3b-a924-b42786515b65",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fc2f9e74-0a62-4e6e-b1ab-453ad28761e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "from utils.train import Build\n",
    "from utils.process import Assemble\n",
    "assemble = Assemble()\n",
    "import pickle as pkl\n",
    "\n",
    "with open('data.pickle', 'rb') as f:\n",
    "    test_dict = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9b216336-91c4-4119-aaef-a8d65f8a24fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers1 = [\n",
    "        layers.Dense(300, activation=\"relu\"),\n",
    "        layers.Dense(225, activation=\"relu\"),\n",
    "        layers.Dense(135, activation=\"relu\"),\n",
    "        layers.Dense(80, activation=\"relu\"),\n",
    "        layers.Dense(50, activation=\"relu\"),\n",
    "        layers.Dense(20, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"relu\"),\n",
    "        layers.Dense(1),\n",
    "    ]\n",
    "\n",
    "layers2 = [\n",
    "        layers.Dense(315, activation=\"relu\"),\n",
    "        layers.Dense(275, activation=\"relu\"),\n",
    "        layers.Dense(225, activation=\"relu\"),\n",
    "        layers.Dense(185, activation=\"relu\"),\n",
    "        layers.Dense(150, activation=\"relu\"),\n",
    "        layers.Dense(120, activation=\"relu\"),\n",
    "        layers.Dense(100, activation=\"relu\"),\n",
    "        layers.Dense(85, activation=\"relu\"),\n",
    "        layers.Dense(65, activation=\"relu\"),\n",
    "        layers.Dense(40, activation=\"relu\"),\n",
    "        layers.Dense(25, activation=\"relu\"),\n",
    "        layers.Dense(15, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"relu\"),\n",
    "        layers.Dense(5, activation=\"relu\"),\n",
    "        layers.Dense(1),\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3b4565a7-1fe4-40f8-96e2-cbee3bcedfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = [\n",
    "        layers.Dense(8, activation=\"relu\"),\n",
    "        layers.Dense(5, activation=\"relu\"),\n",
    "        layers.Dense(2, activation='relu')\n",
    "    ]\n",
    "\n",
    "decoder = [\n",
    "        layers.Dense(5, activation=\"relu\"),\n",
    "        layers.Dense(8, activation=\"relu\"),\n",
    "        layers.Dense(19, activation ='relu')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8a7adf64-7e7e-4be7-9179-e67973c7f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [[{'model': 'ANN1', 'layers':layers1 , 'compile_parameters':{'optimizer': RMSprop(), 'loss':'mse'}, 'fit_parameters':{'batch_size':250, 'epochs':50}},\n",
    "          {'feature_selection': ['SFM1', {}], 'dimensionality_reduction': ['AE1', {'encoder_layers':encoder, 'decoder_layers':decoder, 'compile_parameters':{'optimizer': Adam(), 'loss':'mse'}}]}],\n",
    "          [{'model':'ANN2', 'layers': layers2, 'compile_parameters':{'optimizer': RMSprop(), 'loss':'mse'}, 'fit_parameters':{'batch_size':250, 'epochs':50}}]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "92c589c4-993a-47e7-bfb9-1a209881dbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = test_dict['data']['DF1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9dfb3116-1ecf-4b6a-903e-e323626db6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training deeplearning model ANN1 for DF1\n",
      "Epoch 1/50\n",
      "39/39 [==============================] - 1s 5ms/step - loss: 4695.1143\n",
      "Epoch 2/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1838.0430\n",
      "Epoch 3/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1586.4794\n",
      "Epoch 4/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1484.0018\n",
      "Epoch 5/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1311.7924\n",
      "Epoch 6/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1250.4038\n",
      "Epoch 7/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1194.4073\n",
      "Epoch 8/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1128.8922\n",
      "Epoch 9/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1025.4325\n",
      "Epoch 10/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1074.4216\n",
      "Epoch 11/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1006.9481\n",
      "Epoch 12/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 991.5653\n",
      "Epoch 13/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 918.5856\n",
      "Epoch 14/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 877.2394\n",
      "Epoch 15/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 912.7516\n",
      "Epoch 16/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 893.0233\n",
      "Epoch 17/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 875.7330\n",
      "Epoch 18/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 856.1238\n",
      "Epoch 19/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 847.3306\n",
      "Epoch 20/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 833.2264\n",
      "Epoch 21/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 811.1089\n",
      "Epoch 22/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 753.8500\n",
      "Epoch 23/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 790.6181\n",
      "Epoch 24/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 764.7405\n",
      "Epoch 25/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 698.0212\n",
      "Epoch 26/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 768.2345\n",
      "Epoch 27/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 769.3389\n",
      "Epoch 28/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 732.0850\n",
      "Epoch 29/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 691.0303\n",
      "Epoch 30/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 703.3591\n",
      "Epoch 31/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 648.9222\n",
      "Epoch 32/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 739.7454\n",
      "Epoch 33/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 644.4158\n",
      "Epoch 34/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 670.3068\n",
      "Epoch 35/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 669.4153\n",
      "Epoch 36/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 672.6245\n",
      "Epoch 37/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 627.5256\n",
      "Epoch 38/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 614.8754\n",
      "Epoch 39/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 659.5432\n",
      "Epoch 40/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 598.2486\n",
      "Epoch 41/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 640.4961\n",
      "Epoch 42/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 614.1414\n",
      "Epoch 43/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 587.3536\n",
      "Epoch 44/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 579.6369\n",
      "Epoch 45/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 578.9252\n",
      "Epoch 46/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 593.5223\n",
      "Epoch 47/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 590.8452\n",
      "Epoch 48/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 581.4128\n",
      "Epoch 49/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 545.7794\n",
      "Epoch 50/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 586.9637\n",
      "Training done!\n",
      "\n",
      "Training deeplearning model ANN2 for DF1\n",
      "Epoch 1/50\n",
      "39/39 [==============================] - 1s 8ms/step - loss: 6068.1113\n",
      "Epoch 2/50\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 2919.6655\n",
      "Epoch 3/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 2543.3894\n",
      "Epoch 4/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 2494.2732\n",
      "Epoch 5/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 2249.4780\n",
      "Epoch 6/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 2161.6504\n",
      "Epoch 7/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 2009.7440\n",
      "Epoch 8/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1994.7202\n",
      "Epoch 9/50\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1895.2544\n",
      "Epoch 10/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 2002.3556\n",
      "Epoch 11/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1746.1674\n",
      "Epoch 12/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1745.0990\n",
      "Epoch 13/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1692.4781\n",
      "Epoch 14/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1742.4045\n",
      "Epoch 15/50\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 1631.9414\n",
      "Epoch 16/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1668.8429\n",
      "Epoch 17/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1447.6619\n",
      "Epoch 18/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1592.7788\n",
      "Epoch 19/50\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1484.7076\n",
      "Epoch 20/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1521.9902\n",
      "Epoch 21/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1416.5532\n",
      "Epoch 22/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1492.0560\n",
      "Epoch 23/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1432.6476\n",
      "Epoch 24/50\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1427.0315\n",
      "Epoch 25/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1427.1091\n",
      "Epoch 26/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1311.9070\n",
      "Epoch 27/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1343.4620\n",
      "Epoch 28/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1174.9586\n",
      "Epoch 29/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1388.0425\n",
      "Epoch 30/50\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 1270.9213\n",
      "Epoch 31/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1077.1505\n",
      "Epoch 32/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1393.0450\n",
      "Epoch 33/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1220.2272\n",
      "Epoch 34/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1241.7852\n",
      "Epoch 35/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1165.9409\n",
      "Epoch 36/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1196.4091\n",
      "Epoch 37/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1164.0078\n",
      "Epoch 38/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1197.3888\n",
      "Epoch 39/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1128.5978\n",
      "Epoch 40/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1102.6887\n",
      "Epoch 41/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1128.4495\n",
      "Epoch 42/50\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 1118.5186\n",
      "Epoch 43/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1081.3645\n",
      "Epoch 44/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1115.5660\n",
      "Epoch 45/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1047.0820\n",
      "Epoch 46/50\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1076.9117\n",
      "Epoch 47/50\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1058.2992\n",
      "Epoch 48/50\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1019.6582\n",
      "Epoch 49/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1074.7703\n",
      "Epoch 50/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1010.8754\n",
      "Training done!\n",
      "\n",
      "Training deeplearning model ANN1 for DF2\n",
      "Epoch 1/50\n",
      "39/39 [==============================] - 1s 5ms/step - loss: 6115.4932\n",
      "Epoch 2/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1849.7795\n",
      "Epoch 3/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1642.8698\n",
      "Epoch 4/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1500.4985\n",
      "Epoch 5/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1402.1722\n",
      "Epoch 6/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1384.4042\n",
      "Epoch 7/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1397.0685\n",
      "Epoch 8/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1246.6877\n",
      "Epoch 9/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1315.0112\n",
      "Epoch 10/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1236.6173\n",
      "Epoch 11/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1196.6106\n",
      "Epoch 12/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1158.6758\n",
      "Epoch 13/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1220.9673\n",
      "Epoch 14/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1103.6925\n",
      "Epoch 15/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1168.3839\n",
      "Epoch 16/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1149.8135\n",
      "Epoch 17/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1127.8278\n",
      "Epoch 18/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1094.1265\n",
      "Epoch 19/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1085.8892\n",
      "Epoch 20/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1097.7719\n",
      "Epoch 21/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1051.0984\n",
      "Epoch 22/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1094.8423\n",
      "Epoch 23/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1048.9706\n",
      "Epoch 24/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1008.5872\n",
      "Epoch 25/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1089.7559\n",
      "Epoch 26/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1028.2598\n",
      "Epoch 27/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1042.1644\n",
      "Epoch 28/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1043.1248\n",
      "Epoch 29/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1028.3270\n",
      "Epoch 30/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 992.1275\n",
      "Epoch 31/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1009.8057\n",
      "Epoch 32/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1030.8590\n",
      "Epoch 33/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1012.1223\n",
      "Epoch 34/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1015.2671\n",
      "Epoch 35/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1003.2620\n",
      "Epoch 36/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1008.3787\n",
      "Epoch 37/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1001.0481\n",
      "Epoch 38/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 990.0590\n",
      "Epoch 39/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 982.7664\n",
      "Epoch 40/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 950.1436\n",
      "Epoch 41/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1028.9199\n",
      "Epoch 42/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 935.7924\n",
      "Epoch 43/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1008.8939\n",
      "Epoch 44/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 947.0573\n",
      "Epoch 45/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1000.3958\n",
      "Epoch 46/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 940.1702\n",
      "Epoch 47/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 998.6078\n",
      "Epoch 48/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 952.6447\n",
      "Epoch 49/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 939.8102\n",
      "Epoch 50/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 948.5045\n",
      "Training done!\n",
      "\n",
      "Training deeplearning model ANN2 for DF2\n",
      "Epoch 1/50\n",
      "39/39 [==============================] - 1s 7ms/step - loss: 6802.5420\n",
      "Epoch 2/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 2488.0100\n",
      "Epoch 3/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 2252.4519\n",
      "Epoch 4/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 2043.7046\n",
      "Epoch 5/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1948.0439\n",
      "Epoch 6/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1946.8369\n",
      "Epoch 7/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1875.3406\n",
      "Epoch 8/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1803.5619\n",
      "Epoch 9/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1741.2045\n",
      "Epoch 10/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1746.2461\n",
      "Epoch 11/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1653.7328\n",
      "Epoch 12/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1681.4066\n",
      "Epoch 13/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1559.4283\n",
      "Epoch 14/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1725.2212\n",
      "Epoch 15/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1608.6783\n",
      "Epoch 16/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1533.1178\n",
      "Epoch 17/50\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 1525.5959\n",
      "Epoch 18/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1482.8507\n",
      "Epoch 19/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1692.8241\n",
      "Epoch 20/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1451.9408\n",
      "Epoch 21/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1470.2802\n",
      "Epoch 22/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1517.4672\n",
      "Epoch 23/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1569.7179\n",
      "Epoch 24/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1445.6819\n",
      "Epoch 25/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1409.3971\n",
      "Epoch 26/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1490.7050\n",
      "Epoch 27/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1422.5470\n",
      "Epoch 28/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1402.0835\n",
      "Epoch 29/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1466.5106\n",
      "Epoch 30/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1345.8040\n",
      "Epoch 31/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1387.7856\n",
      "Epoch 32/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1401.2764\n",
      "Epoch 33/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1320.5660\n",
      "Epoch 34/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1349.2572\n",
      "Epoch 35/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1301.1637\n",
      "Epoch 36/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1335.3810\n",
      "Epoch 37/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1377.3008\n",
      "Epoch 38/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1280.1606\n",
      "Epoch 39/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1336.2531\n",
      "Epoch 40/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1332.9830\n",
      "Epoch 41/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1350.4308\n",
      "Epoch 42/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1267.2192\n",
      "Epoch 43/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1327.2408\n",
      "Epoch 44/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1310.5536\n",
      "Epoch 45/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1277.7588\n",
      "Epoch 46/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1303.0215\n",
      "Epoch 47/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1299.9597\n",
      "Epoch 48/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1343.9371\n",
      "Epoch 49/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1203.6572\n",
      "Epoch 50/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1283.4213\n",
      "Training done!\n",
      "\n",
      "Training deeplearning model ANN1 for DF3\n",
      "Epoch 1/50\n",
      "39/39 [==============================] - 1s 5ms/step - loss: 4728.8550\n",
      "Epoch 2/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1684.3254\n",
      "Epoch 3/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1501.5099\n",
      "Epoch 4/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1368.1907\n",
      "Epoch 5/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1244.6744\n",
      "Epoch 6/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1272.6326\n",
      "Epoch 7/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1192.6544\n",
      "Epoch 8/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1192.4570\n",
      "Epoch 9/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1176.8341\n",
      "Epoch 10/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1125.9542\n",
      "Epoch 11/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1146.1987\n",
      "Epoch 12/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1126.6592\n",
      "Epoch 13/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1106.4017\n",
      "Epoch 14/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1079.1948\n",
      "Epoch 15/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1079.3807\n",
      "Epoch 16/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1095.8505\n",
      "Epoch 17/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1063.8534\n",
      "Epoch 18/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1078.9785\n",
      "Epoch 19/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1079.5051\n",
      "Epoch 20/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1007.0084\n",
      "Epoch 21/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1096.8965\n",
      "Epoch 22/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1057.1495\n",
      "Epoch 23/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1015.1133\n",
      "Epoch 24/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1025.9780\n",
      "Epoch 25/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1044.9583\n",
      "Epoch 26/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1017.3436\n",
      "Epoch 27/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1048.2831\n",
      "Epoch 28/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1028.9773\n",
      "Epoch 29/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 973.7961\n",
      "Epoch 30/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1017.6993\n",
      "Epoch 31/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1032.5183\n",
      "Epoch 32/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 999.2604\n",
      "Epoch 33/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1002.2462\n",
      "Epoch 34/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1012.1813\n",
      "Epoch 35/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1008.9618\n",
      "Epoch 36/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 978.2378\n",
      "Epoch 37/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1005.2329\n",
      "Epoch 38/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 986.0297\n",
      "Epoch 39/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 996.7272\n",
      "Epoch 40/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1014.2562\n",
      "Epoch 41/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 996.5961\n",
      "Epoch 42/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 978.3809\n",
      "Epoch 43/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 993.4338\n",
      "Epoch 44/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 984.7114\n",
      "Epoch 45/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 972.1691\n",
      "Epoch 46/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 948.2596\n",
      "Epoch 47/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 989.9276\n",
      "Epoch 48/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 972.7233\n",
      "Epoch 49/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 957.0087\n",
      "Epoch 50/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 994.5674\n",
      "Training done!\n",
      "\n",
      "Training deeplearning model ANN2 for DF3\n",
      "Epoch 1/50\n",
      "39/39 [==============================] - 1s 8ms/step - loss: 5959.9902\n",
      "Epoch 2/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 2153.5164\n",
      "Epoch 3/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1956.8302\n",
      "Epoch 4/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1902.1252\n",
      "Epoch 5/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1652.6724\n",
      "Epoch 6/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1658.6309\n",
      "Epoch 7/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1643.3518\n",
      "Epoch 8/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1562.1484\n",
      "Epoch 9/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1568.8562\n",
      "Epoch 10/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1490.3418\n",
      "Epoch 11/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1532.7689\n",
      "Epoch 12/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1421.1829\n",
      "Epoch 13/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1413.1813\n",
      "Epoch 14/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1463.0721\n",
      "Epoch 15/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1421.0673\n",
      "Epoch 16/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1330.8749\n",
      "Epoch 17/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1451.6708\n",
      "Epoch 18/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1320.5880\n",
      "Epoch 19/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1375.7167\n",
      "Epoch 20/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1394.4109\n",
      "Epoch 21/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1274.8171\n",
      "Epoch 22/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1357.3650\n",
      "Epoch 23/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1364.3156\n",
      "Epoch 24/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1280.5087\n",
      "Epoch 25/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1399.9192\n",
      "Epoch 26/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1349.3336\n",
      "Epoch 27/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1307.9011\n",
      "Epoch 28/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1388.8890\n",
      "Epoch 29/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1303.2546\n",
      "Epoch 30/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1334.3346\n",
      "Epoch 31/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1262.0304\n",
      "Epoch 32/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1292.9949\n",
      "Epoch 33/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1355.8992\n",
      "Epoch 34/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1237.3818\n",
      "Epoch 35/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1281.7906\n",
      "Epoch 36/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1297.7269\n",
      "Epoch 37/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1275.3672\n",
      "Epoch 38/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1298.3943\n",
      "Epoch 39/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1246.1594\n",
      "Epoch 40/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1266.5690\n",
      "Epoch 41/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1274.6447\n",
      "Epoch 42/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1266.1597\n",
      "Epoch 43/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1181.7562\n",
      "Epoch 44/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1269.8043\n",
      "Epoch 45/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1241.2256\n",
      "Epoch 46/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1238.4673\n",
      "Epoch 47/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1209.8008\n",
      "Epoch 48/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1215.7369\n",
      "Epoch 49/50\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1205.2212\n",
      "Epoch 50/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1234.8274\n",
      "Training done!\n",
      "\n",
      "Training deeplearning model ANN1 for DF4\n",
      "Epoch 1/50\n",
      "39/39 [==============================] - 1s 6ms/step - loss: 4766.0376\n",
      "Epoch 2/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1710.3221\n",
      "Epoch 3/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1523.1437\n",
      "Epoch 4/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1403.3363\n",
      "Epoch 5/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1347.5911\n",
      "Epoch 6/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1313.2394\n",
      "Epoch 7/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1250.1760\n",
      "Epoch 8/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1211.1655\n",
      "Epoch 9/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1146.5387\n",
      "Epoch 10/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1158.4974\n",
      "Epoch 11/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1088.3612\n",
      "Epoch 12/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1140.4375\n",
      "Epoch 13/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1051.3730\n",
      "Epoch 14/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1150.0631\n",
      "Epoch 15/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1044.8114\n",
      "Epoch 16/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1129.0376\n",
      "Epoch 17/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1055.8040\n",
      "Epoch 18/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1049.1610\n",
      "Epoch 19/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1086.1083\n",
      "Epoch 20/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1043.5034\n",
      "Epoch 21/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1103.0947\n",
      "Epoch 22/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 995.9633\n",
      "Epoch 23/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1032.3408\n",
      "Epoch 24/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1005.7339\n",
      "Epoch 25/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1038.0868\n",
      "Epoch 26/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1022.4440\n",
      "Epoch 27/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1012.4223\n",
      "Epoch 28/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 998.3190\n",
      "Epoch 29/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1000.5659\n",
      "Epoch 30/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 974.0646\n",
      "Epoch 31/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1011.4076\n",
      "Epoch 32/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 976.4865\n",
      "Epoch 33/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1021.0446\n",
      "Epoch 34/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 985.8663\n",
      "Epoch 35/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 978.2305\n",
      "Epoch 36/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1021.6022\n",
      "Epoch 37/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 978.7274\n",
      "Epoch 38/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 976.7475\n",
      "Epoch 39/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 952.6586\n",
      "Epoch 40/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1001.7431\n",
      "Epoch 41/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 986.4839\n",
      "Epoch 42/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 961.7433\n",
      "Epoch 43/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 993.5237\n",
      "Epoch 44/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 930.9378\n",
      "Epoch 45/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 959.6973\n",
      "Epoch 46/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 954.0411\n",
      "Epoch 47/50\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 960.9046\n",
      "Epoch 48/50\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 962.3331\n",
      "Epoch 49/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 939.1171\n",
      "Epoch 50/50\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 955.4639\n",
      "Training done!\n",
      "\n",
      "Training deeplearning model ANN2 for DF4\n",
      "Epoch 1/50\n",
      "39/39 [==============================] - 1s 8ms/step - loss: 4961.6855\n",
      "Epoch 2/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1925.9421\n",
      "Epoch 3/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1824.6008\n",
      "Epoch 4/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1675.7982\n",
      "Epoch 5/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1618.0085\n",
      "Epoch 6/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1524.3704\n",
      "Epoch 7/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1532.1851\n",
      "Epoch 8/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1516.5145\n",
      "Epoch 9/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1468.2443\n",
      "Epoch 10/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1409.0887\n",
      "Epoch 11/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1473.0492\n",
      "Epoch 12/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1447.1119\n",
      "Epoch 13/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1405.7062\n",
      "Epoch 14/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1247.2350\n",
      "Epoch 15/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1416.7244\n",
      "Epoch 16/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1318.2235\n",
      "Epoch 17/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1359.0881\n",
      "Epoch 18/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1330.3748\n",
      "Epoch 19/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1238.7471\n",
      "Epoch 20/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1302.4833\n",
      "Epoch 21/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1314.5811\n",
      "Epoch 22/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1263.7972\n",
      "Epoch 23/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1287.7542\n",
      "Epoch 24/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1206.6204\n",
      "Epoch 25/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1335.1162\n",
      "Epoch 26/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1239.8755\n",
      "Epoch 27/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1297.6864\n",
      "Epoch 28/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1190.1218\n",
      "Epoch 29/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1262.8074\n",
      "Epoch 30/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1309.1660\n",
      "Epoch 31/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1225.2950\n",
      "Epoch 32/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1275.1901\n",
      "Epoch 33/50\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 1218.7482\n",
      "Epoch 34/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1217.2516\n",
      "Epoch 35/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1263.7269\n",
      "Epoch 36/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1183.3378\n",
      "Epoch 37/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1185.4972\n",
      "Epoch 38/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1240.7422\n",
      "Epoch 39/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1251.4303\n",
      "Epoch 40/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1205.2754\n",
      "Epoch 41/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1218.7184\n",
      "Epoch 42/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1161.1206\n",
      "Epoch 43/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1219.5646\n",
      "Epoch 44/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1138.2100\n",
      "Epoch 45/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1202.9847\n",
      "Epoch 46/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1228.1938\n",
      "Epoch 47/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1189.7101\n",
      "Epoch 48/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1141.4127\n",
      "Epoch 49/50\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1222.6710\n",
      "Epoch 50/50\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1188.5514\n",
      "Training done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build = Build(test_dict)\n",
    "build.build_deep_learning_models(models, 'Satış')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3df09b76-bb1b-4338-9f99-f6f8bd6e210b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'predictions', 'models', 'X_test', 'y_test', 'results', 'test_tables'])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4ec5ea0e-9c4b-48c9-81ff-600699adb375",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict['test_tables'] = assemble.assemble_test_tables(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "09310f1e-c446-4ddc-a318-1c3393b36343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEPE</th>\n",
       "      <th>MPE</th>\n",
       "      <th>MEAE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>NRMSE</th>\n",
       "      <th>STD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALGORITHM</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DF1ANN1</th>\n",
       "      <td>11.200</td>\n",
       "      <td>12.492</td>\n",
       "      <td>15.647</td>\n",
       "      <td>22.731</td>\n",
       "      <td>1014.043</td>\n",
       "      <td>31.844</td>\n",
       "      <td>0.035070</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF1ANN2</th>\n",
       "      <td>15.946</td>\n",
       "      <td>16.396</td>\n",
       "      <td>22.803</td>\n",
       "      <td>31.281</td>\n",
       "      <td>1809.048</td>\n",
       "      <td>42.533</td>\n",
       "      <td>0.046843</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF2ANN1</th>\n",
       "      <td>12.072</td>\n",
       "      <td>13.141</td>\n",
       "      <td>16.730</td>\n",
       "      <td>24.596</td>\n",
       "      <td>1231.492</td>\n",
       "      <td>35.093</td>\n",
       "      <td>0.038649</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF2ANN2</th>\n",
       "      <td>11.472</td>\n",
       "      <td>15.015</td>\n",
       "      <td>17.572</td>\n",
       "      <td>23.792</td>\n",
       "      <td>1062.856</td>\n",
       "      <td>32.601</td>\n",
       "      <td>0.035904</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF3ANN1</th>\n",
       "      <td>10.578</td>\n",
       "      <td>12.863</td>\n",
       "      <td>15.222</td>\n",
       "      <td>21.294</td>\n",
       "      <td>845.933</td>\n",
       "      <td>29.085</td>\n",
       "      <td>0.032032</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF3ANN2</th>\n",
       "      <td>16.982</td>\n",
       "      <td>17.519</td>\n",
       "      <td>24.794</td>\n",
       "      <td>32.526</td>\n",
       "      <td>1923.603</td>\n",
       "      <td>43.859</td>\n",
       "      <td>0.048303</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF4ANN1</th>\n",
       "      <td>10.499</td>\n",
       "      <td>12.981</td>\n",
       "      <td>16.105</td>\n",
       "      <td>21.446</td>\n",
       "      <td>852.754</td>\n",
       "      <td>29.202</td>\n",
       "      <td>0.032161</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF4ANN2</th>\n",
       "      <td>15.928</td>\n",
       "      <td>16.350</td>\n",
       "      <td>22.685</td>\n",
       "      <td>31.956</td>\n",
       "      <td>2002.233</td>\n",
       "      <td>44.746</td>\n",
       "      <td>0.049280</td>\n",
       "      <td>109.719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MEPE     MPE    MEAE     MAE       MSE    RMSE     NRMSE      STD\n",
       "ALGORITHM                                                                     \n",
       "DF1ANN1    11.200  12.492  15.647  22.731  1014.043  31.844  0.035070  109.719\n",
       "DF1ANN2    15.946  16.396  22.803  31.281  1809.048  42.533  0.046843  109.719\n",
       "DF2ANN1    12.072  13.141  16.730  24.596  1231.492  35.093  0.038649  109.719\n",
       "DF2ANN2    11.472  15.015  17.572  23.792  1062.856  32.601  0.035904  109.719\n",
       "DF3ANN1    10.578  12.863  15.222  21.294   845.933  29.085  0.032032  109.719\n",
       "DF3ANN2    16.982  17.519  24.794  32.526  1923.603  43.859  0.048303  109.719\n",
       "DF4ANN1    10.499  12.981  16.105  21.446   852.754  29.202  0.032161  109.719\n",
       "DF4ANN2    15.928  16.350  22.685  31.956  2002.233  44.746  0.049280  109.719"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assemble.assemble_error_values(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31aa9b60-b995-4276-a99c-b2d041304236",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
